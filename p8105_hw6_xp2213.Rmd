---
title: "p8105 Homework 6"
output: github_document
date: "2024-12-03"
---
Name [UNI]: Xi Peng [xp2213]

```{r setup, include=FALSE}
library(tidyverse)
library(modelr)
library(broom)
library(purrr)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(924)
```

# Question 1: 2017 Central Park weather data
```{r}
# Dataset download and processes.
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

# Define a bootstrap sampling function.
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}

# Bootstrap resampling.
boot_straps_result = tibble(strap_number = 1:5000) |> 
  mutate(
    strap_sample = map(strap_number, ~ boot_sample(weather_df)),
    models = map(strap_sample, ~ lm(tmax ~ tmin, data = .x)),
    results = map(models, tidy),                         
    r_squared = map_dbl(models, ~ glance(.x)$r.squared), 
    log_beta_product = map_dbl(models, ~ {       
      coefs = tidy(.x)  
      beta_0 = coefs |> filter(term == "(Intercept)") |> pull(estimate)
      beta_1 = coefs |> filter(term == "tmin") |> pull(estimate)
      log(abs(beta_0 * beta_1))
    })
  )

boot_straps_result
```
<br>
Plot the distribution of the estimates of the two quantities.
```{r}
boot_straps_plot = 
  boot_straps_result |>
  select(r_squared, log_beta_product) |> 
  pivot_longer(cols = everything(), names_to = "metric", values_to = "value") |> 
  ggplot(aes(x = value)) +
  geom_density(alpha = 0.3) +
  facet_wrap(~metric, scales = "free") +
  labs(
    title = "Bootstrap Distributions of R^2 and log(β0 * β1)",
    x = "Value",
    y = "Density"
  )

boot_straps_plot
```

Both distributions show clear, bell-shaped curves with minimal skewness, indicating that these statistics are stable and reliable across different bootstrap samples.The plot indicates a strong linear relationship between tmax and tmin in the weather data, as reflected by the consistently high r_squared values and stable log_beta_product values across 5000 bootstrap samples. The narrow distribution of r_squared values demonstrates that the model explains a substantial proportion of the variance in tmax, while the consistency of the log_beta_product values indicates minimal variability in the relationship between the coefficients. The large sample size of 5000 ensures that the distributions capture the true underlying pattern with minimal variation across resampled datasets.

<br>
95% confidence interval for the two quantities.
```{r}
CI_result = boot_straps_result |> 
  summarize(
    r_squared_CI = list(quantile(r_squared, c(0.025,0.975))),
    log_beta_product_CI = list(quantile(log_beta_product, c(0.025, 0.975)))
  ) 

knitr::kable(CI_result)
```

# Question 2: Homicide Rates Across U.S. Cities
```{r}
url = "https://raw.githubusercontent.com/washingtonpost/data-homicides/refs/heads/master/homicide-data.csv"

homi_data = read_csv(url) |> 
  janitor::clean_names() |> 
  mutate(
    city_state = str_c(city, ", ", state),
    resolved = as.numeric(disposition == "Closed by arrest"),
    victim_age = as.numeric(victim_age)
  ) |> 
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black"), 
    !is.na(victim_age)
  )
```

In this step, the original dataset is imported, and two key variables are created: city_state, which combines the city and state names, and a binary variable, resolved, indicating whether the homicide was solved. Cities that do not report victim race, such as Dallas, TX; Phoenix, AZ; and Kansas City, MO, are excluded, along with Tulsa, AL, due to a data entry error. The analysis is further narrowed to include only cases where victim_race is recorded as either "White" or "Black" and victim_age is confirmed as a numeric value.

<br>
Analyze for Baltimore, MD
```{r}
# Filter data for Baltimore, MD
Bal_MD = homi_data |> 
  filter(city_state == "Baltimore, MD") 

# Fit a logistic regression
Bal_MD_fit = glm(
  resolved ~ victim_age + victim_race + victim_sex,
  data = Bal_MD, family = binomial()
) |> 
  tidy()

knitr::kable(Bal_MD_fit, digits = 3)

ORmale_Bal_MD = Bal_MD_fit |> 
  mutate(
    OR = exp(estimate),
    lower_CI = exp(estimate - 1.96 * std.error),
    upper_CI = exp(estimate + 1.96 * std.error)
  ) |> 
  filter(term == "victim_sexMale") |> 
  select(term, OR, lower_CI, upper_CI)

knitr::kable(ORmale_Bal_MD, digits = 3)
```

```{r}
# Fit a logistic regression for each city
all_city_results <- homi_data |> 
  group_by(city_state) |> 
  nest() |> 
  mutate(
    model = map(data, ~ glm(resolved ~ victim_age + victim_race + victim_sex, 
                            data = .x, family = binomial())),
    tidy_results = map(model, ~ tidy(.x) |> 
                         filter(term == "victim_sexMale") |> 
                         mutate(
                           OR = exp(estimate),
                           lower_CI = exp(estimate - 1.96 * std.error),
                           upper_CI = exp(estimate + 1.96 * std.error)
                         ))
  ) |> 
  unnest(tidy_results) |> 
  select(city_state, OR, lower_CI, upper_CI)

knitr::kable(all_city_results, digits = 3)
```

<br>
Plot of the estimated ORs and CIs for all city.
```{r}
all_city_results_plot = 
  all_city_results |> 
  ggplot(aes(x = reorder(city_state, OR), y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = lower_CI, ymax = upper_CI), width = 0.2) +
  coord_flip() +
  labs(
    title = "Odds Ratios for Solving Homicides (Male vs Female Victims)",
    x = "City",
    y = "Odds Ratio"
  )

all_city_results_plot
```

The plot reveals that in most cities, the ORs are below 1, suggesting that cases involving female victims are more likely to be resolved compared to those involving male victims. However, the CIs for the majority of cities include the null value of 1, indicating that these differences in case resolution rates between male and female victims are not statistically significant. Cities such as Stockton, CA, Fresno, CA, Richmond, VA, Tampa, FL, and San Bernardino, CA exhibit notably wider confidence intervals, which may reflect greater variability or smaller sample sizes relative to other cities. Albuquerque, NM stands out with a substantially higher OR and an exceptionally wide CI, making it a potential outlier that warrants further investigation to understand the underlying factors contributing to this result.

# Question 3: Child’s birthweight
```{r}
# Dataset import and clean
child_birthweight =
    read_csv("data/birthweight.csv", na = c("NA", "", ".", " ")) |> 
  janitor::clean_names() |> 
  drop_na() |> 
  mutate(
    babysex = factor(babysex, levels = c(1, 2), labels = c("Male", "Female")),
    frace = factor(frace, levels = c(1, 2, 3, 4, 8, 9), labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown")),
    mrace = factor(mrace, levels = c(1, 2, 3, 4, 8), labels = c("White", "Black", "Asian", "Puerto Rican", "Other")),
    malform = factor(malform, levels = c(0, 1), labels = c("Absent", "Present")),
  )
```

During this step, the original dataset was imported, and necessary variables (babysex, frace, mrace, and malform) were converted from numeric to factors to ensure they are treated as categorical variables in the analysis. Missing values were checked.

<br>
Propose a regression model for birthweight.
```{r}
hypo_birthw_model = 
  lm(bwt ~ babysex + delwt + gaweeks + mheight + momage + ppbmi + ppwt + smoken + wtgain + parity + pnumlbw + pnumsga, data = child_birthweight 
     )

hypo_birthw_model |> 
  glance() |> 
  knitr::kable(digits = 3)
``` 

The modeling process is designed based on based on a hypothesized structure by identifying biological and behavioral factors known to influence birthweight. First, it is well-established that birthweight differs between male and female infants, making babysex a critical variable. Maternal physical characteristics significantly impact birthweight, including delwt (mother’s weight at delivery), gaweeks (gestational age in weeks), mheight (mother’s height), momage (mother’s age at delivery), ppbmi (mother’s pre-pregnancy BMI), and ppwt (mother’s pre-pregnancy weight). Additionally, maternal health behaviors, such as smoken (average number of cigarettes smoked per day during pregnancy) and wtgain (mother’s weight gain during pregnancy), play a pivotal role in determining birth outcomes. Lastly, prior obstetric history, including parity (number of previous live births), pnumlbw (number of previous low birthweight babies), and pnumgsa (number of prior small-for-gestational-age babies), is incorporated to account for its influence on birthweight.

<br>
Plot of model residuals against fitted values.
```{r}
child_birthweight_plot = child_birthweight |> 
  add_predictions(hypo_birthw_model) |> 
  add_residuals(hypo_birthw_model) |> 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3) +
  geom_hline(yintercept = 0, color = "red") +
  labs(
    title = "Residuals vs Fitted Values",
    x = "Fitted Values",
    y = "Residuals"
  )

child_birthweight_plot
```

<br>
Model comparison.
```{r}
# Fit the two models based on the instructions.
model_1 = 
  lm(bwt ~ blength + gaweeks, data = child_birthweight)

model_2 = 
  lm(bwt ~ bhead + blength + babysex + bhead:blength + bhead:babysex + blength:babysex + bhead:blength:babysex, data = child_birthweight)

summary(model_1)
summary(model_2)

cv_df =
  crossv_mc(child_birthweight, 100) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) |> 
  mutate(
    hypo_mod = map(train, ~ lm(bwt ~ babysex + delwt + gaweeks + mheight + momage + ppbmi + ppwt + smoken + wtgain + parity + pnumlbw + pnumsga, data = .x)),
    model1_mod = map(train, ~ lm(bwt ~ blength + gaweeks, data = .x)),
    model2_mod = map(train, ~ lm(bwt ~ bhead + blength + babysex + bhead:blength + bhead:babysex + blength:babysex + bhead:blength:babysex, data = .x))
  ) |> 
  mutate(
    rmse_hypo = map2_dbl(hypo_mod, test, ~rmse(model = .x, data = .y)),
    rmse_model1 = map2_dbl(model1_mod, test, ~rmse(model = .x, data = .y)),
    rmse_model2 = map2_dbl(model2_mod, test, ~rmse(model = .x, data = .y))
  )

# Visualization of prediction error distributions
cv_df_plot = cv_df |> 
  select(starts_with("rmse")) |>
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) |>
  mutate(model = fct_inorder(model)) |>
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() +
  labs(
    title = "Distribution of Prediction Errors Across Models",
    x = "Model",
    y = "rmse"
  )

cv_df_plot
```

The plot depicts the distribution of RMSE values for the three models after 100 cross-validation splits. Among these three models, the "model2," which includes head circumference, length, sex, and all interactions, has the lowest RMSE and the narrowest error distribution, suggesting it provides the most accurate and consistent predictions among the three models.